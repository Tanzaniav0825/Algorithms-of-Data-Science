{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrn78O3/0Z+D80UPka4R3T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tanzaniav0825/Algorithms-of-Data-Science/blob/session-2/Python_code_deliverable_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TbNH6sqbDin-"
      },
      "outputs": [],
      "source": [
        "#Libraries for URL parsing, networking, and utilities.\n",
        "import re\n",
        "import math\n",
        "import json\n",
        "import time\n",
        "import socket\n",
        "from typing import List, Dict, Any, Optional\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "import http.client\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [Purpose] Centralize helpers. This version tightens URL validation so malformed inputs stay invalid.\n",
        "\n",
        "GOOD_NEWS_DOMAINS = {\n",
        "    \"nytimes.com\", \"washingtonpost.com\", \"bbc.com\", \"apnews.com\", \"reuters.com\",\n",
        "    \"theguardian.com\", \"npr.org\", \"wsj.com\", \"financialtimes.com\", \"nature.com\",\n",
        "}\n",
        "URL_SHORTENERS = {\n",
        "    \"bit.ly\", \"tinyurl.com\", \"t.co\", \"goo.gl\", \"ow.ly\", \"is.gd\", \"buff.ly\",\n",
        "    \"rb.gy\", \"rebrand.ly\", \"lnkd.in\"\n",
        "}\n",
        "TRACKING_PARAMS = {\"utm_source\",\"utm_medium\",\"utm_campaign\",\"utm_term\",\"utm_content\",\"gclid\",\"fbclid\"}\n",
        "\n",
        "_SCHEME_RE = re.compile(r'^[a-zA-Z][a-zA-Z0-9+\\-.]*://')\n",
        "# Detect \"http//\" (missing colon) and similar malformed schemes\n",
        "_MALFORMED_SCHEME_RE = re.compile(r'^[a-zA-Z]+//')\n",
        "\n",
        "def _plausible_hostname(host: str) -> bool:\n",
        "    \"\"\"\n",
        "    Lightweight hostname check:\n",
        "      - contains at least one dot\n",
        "      - labels: 1–63 chars, a–z 0–9 -, no label starts/ends with '-'\n",
        "      - final TLD is alphabetic and length 2–24\n",
        "    \"\"\"\n",
        "    host = host.lower()\n",
        "    if \"@\" in host:\n",
        "        host = host.split(\"@\", 1)[-1]\n",
        "    if \":\" in host:\n",
        "        host = host.split(\":\", 1)[0]\n",
        "\n",
        "    if \".\" not in host:\n",
        "        return False\n",
        "    labels = host.split(\".\")\n",
        "    for lab in labels:\n",
        "        if not (1 <= len(lab) <= 63):\n",
        "            return False\n",
        "        if lab[0] == \"-\" or lab[-1] == \"-\":\n",
        "            return False\n",
        "        if not re.fullmatch(r'[a-z0-9-]+', lab):\n",
        "            return False\n",
        "    tld = labels[-1]\n",
        "    if not (2 <= len(tld) <= 24 and tld.isalpha()):\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def safe_parse(url: str):\n",
        "    \"\"\"Parse a URL safely. Returns (parsed, error_msg). Stricter than before.\"\"\"\n",
        "    if not isinstance(url, str):\n",
        "        return None, \"Invalid URL: Input is not a string.\"\n",
        "    url = url.strip()\n",
        "    if not url:\n",
        "        return None, \"Invalid URL: Empty string.\"\n",
        "\n",
        "    # Explicitly reject 'http//...' style (missing colon)\n",
        "    if _MALFORMED_SCHEME_RE.match(url):\n",
        "        return None, \"Invalid URL: Malformed scheme (missing ':').\"\n",
        "\n",
        "    # If scheme is missing, try assuming https://\n",
        "    if not _SCHEME_RE.match(url):\n",
        "        url = \"https://\" + url\n",
        "\n",
        "    try:\n",
        "        parsed = urlparse(url)\n",
        "    except Exception as e:\n",
        "        return None, f\"URL parse error: {e}\"\n",
        "\n",
        "    if not parsed.netloc:\n",
        "        return None, \"Invalid URL: Missing network location (domain).\"\n",
        "\n",
        "    # Final hostname plausibility gate\n",
        "    host = parsed.netloc.lower()\n",
        "    if \"@\" in host:\n",
        "        host = host.split(\"@\", 1)[-1]\n",
        "    if \":\" in host:\n",
        "        host = host.split(\":\", 1)[0]\n",
        "    if not _plausible_hostname(host):\n",
        "        return None, \"Invalid URL: Hostname not plausible.\"\n",
        "\n",
        "    return parsed, None\n",
        "\n",
        "def domain_from_netloc(netloc: str) -> str:\n",
        "    \"\"\"Extract base domain (very basic; not a full PSL parser).\"\"\"\n",
        "    netloc = netloc.lower()\n",
        "    if \"@\" in netloc:\n",
        "        netloc = netloc.split(\"@\", 1)[1]\n",
        "    if \":\" in netloc:\n",
        "        netloc = netloc.split(\":\", 1)[0]\n",
        "    return netloc\n",
        "\n",
        "def is_reachable_via_head(parsed, timeout=2.0) -> Optional[int]:\n",
        "    \"\"\"\n",
        "    Attempt a lightweight HEAD request to gauge reachability & status.\n",
        "    Returns HTTP status code or None if we can't reach.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        host = parsed.netloc\n",
        "        path = parsed.path or \"/\"\n",
        "        if parsed.query:\n",
        "            path += \"?\" + parsed.query\n",
        "\n",
        "        if parsed.scheme == \"https\":\n",
        "            conn = http.client.HTTPSConnection(host, timeout=timeout)\n",
        "        elif parsed.scheme == \"http\":\n",
        "            conn = http.client.HTTPConnection(host, timeout=timeout)\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "        conn.request(\"HEAD\", path, headers={\"User-Agent\": \"CredibilityProto/0.1\"})\n",
        "        resp = conn.getresponse()\n",
        "        status = resp.status\n",
        "        conn.close()\n",
        "        return status\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def sigmoid(x: float) -> float:\n",
        "    \"\"\"Map any real number to (0, 1) for a tidy score.\"\"\"\n",
        "    return 1 / (1 + math.exp(-x))\n"
      ],
      "metadata": {
        "id": "9MO4sCopGXFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [Purpose] Simple, explainable heuristics; consistent JSON output.\n",
        "\n",
        "def evaluate_url(url: str, network_check: bool = True, timeout: float = 2.0) -> Dict[str, Any]:\n",
        "    parsed, parse_err = safe_parse(url)\n",
        "    explanation_lines = []\n",
        "    linear_score = 0.0  # accumulate, then squash to (0,1) via sigmoid\n",
        "\n",
        "    if parse_err:\n",
        "        explanation_lines.append(parse_err)\n",
        "        return {\"score\": 0.0, \"explanation\": \" | \".join(explanation_lines)}\n",
        "\n",
        "    scheme = parsed.scheme.lower()\n",
        "    netloc = domain_from_netloc(parsed.netloc)\n",
        "    path = parsed.path or \"/\"\n",
        "    query = parsed.query or \"\"\n",
        "    tld = netloc.split(\".\")[-1] if \".\" in netloc else \"\"\n",
        "\n",
        "    explanation_lines.append(f\"scheme={scheme}, domain={netloc}\")\n",
        "\n",
        "    # 1) Scheme preference\n",
        "    if scheme == \"https\":\n",
        "        linear_score += 0.6\n",
        "        explanation_lines.append(\"+ HTTPS detected (+0.6)\")\n",
        "    elif scheme == \"http\":\n",
        "        linear_score += 0.2\n",
        "        explanation_lines.append(\"+ HTTP detected (+0.2)\")\n",
        "    else:\n",
        "        linear_score -= 0.2\n",
        "        explanation_lines.append(f\"- Non-HTTP(S) scheme '{scheme}' (-0.2)\")\n",
        "\n",
        "    # 2) Domain category\n",
        "    if tld in {\"edu\", \"gov\"}:\n",
        "        linear_score += 1.0\n",
        "        explanation_lines.append(\"+ .edu/.gov top-level domain (+1.0)\")\n",
        "\n",
        "    if any(netloc.endswith(d) for d in GOOD_NEWS_DOMAINS):\n",
        "        linear_score += 0.8\n",
        "        explanation_lines.append(\"+ recognized reputable domain (+0.8)\")\n",
        "\n",
        "    if any(netloc == s or netloc.endswith(\".\" + s) for s in URL_SHORTENERS):\n",
        "        linear_score -= 0.8\n",
        "        explanation_lines.append(\"- URL shortener detected (-0.8)\")\n",
        "\n",
        "    # 3) Suspicious domain patterns\n",
        "    hyphens = netloc.count(\"-\")\n",
        "    digits = sum(c.isdigit() for c in netloc)\n",
        "    if \"xn--\" in netloc:\n",
        "        linear_score -= 0.6\n",
        "        explanation_lines.append(\"- punycode domain (-0.6)\")\n",
        "    if hyphens >= 3:\n",
        "        linear_score -= 0.5\n",
        "        explanation_lines.append(f\"- many hyphens in domain ({hyphens}) (-0.5)\")\n",
        "    if digits >= 5:\n",
        "        linear_score -= 0.4\n",
        "        explanation_lines.append(f\"- many digits in domain ({digits}) (-0.4)\")\n",
        "\n",
        "    # 4) URL complexity\n",
        "    url_str = parsed.geturl()\n",
        "    if len(url_str) > 200:\n",
        "        linear_score -= 0.4\n",
        "        explanation_lines.append(\"- very long URL (>200 chars) (-0.4)\")\n",
        "\n",
        "    q = parse_qs(query)\n",
        "    qp_count = len(q)\n",
        "    if qp_count >= 5:\n",
        "        linear_score -= 0.2\n",
        "        explanation_lines.append(f\"- many query parameters ({qp_count}) (-0.2)\")\n",
        "    if any(p in q for p in TRACKING_PARAMS):\n",
        "        linear_score -= 0.1\n",
        "        explanation_lines.append(\"- common tracking params present (-0.1)\")\n",
        "\n",
        "    # 5) Optional reachability (HEAD)\n",
        "    status = None\n",
        "    if network_check:\n",
        "        status = is_reachable_via_head(parsed, timeout=timeout)\n",
        "        if status is None:\n",
        "            linear_score -= 0.15\n",
        "            explanation_lines.append(\"- could not verify reachability (-0.15)\")\n",
        "        else:\n",
        "            explanation_lines.append(f\"HEAD status={status}\")\n",
        "            if 200 <= status < 300:\n",
        "                linear_score += 0.3\n",
        "                explanation_lines.append(\"+ 2xx status (+0.3)\")\n",
        "            elif 300 <= status < 400:\n",
        "                linear_score += 0.1\n",
        "                explanation_lines.append(\"+ 3xx status (+0.1)\")\n",
        "            elif 400 <= status < 500:\n",
        "                linear_score -= 0.3\n",
        "                explanation_lines.append(\"- 4xx status (-0.3)\")\n",
        "            else:\n",
        "                linear_score -= 0.2\n",
        "                explanation_lines.append(\"- 5xx/other status (-0.2)\")\n",
        "\n",
        "    score = sigmoid(linear_score)\n",
        "    score = max(0.0, min(1.0, score))  # clamp\n",
        "\n",
        "    return {\n",
        "        \"score\": float(round(score, 4)),\n",
        "        \"explanation\": \" | \".join(explanation_lines),\n",
        "    }\n"
      ],
      "metadata": {
        "id": "enB5fc9zGhaE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Score multiple URLs in one call; handy for tests/benchmarks.\n",
        "\n",
        "def evaluate_urls(urls: List[str], network_check: bool = True, timeout: float = 2.0) -> List[Dict[str, Any]]:\n",
        "    results = []\n",
        "    for u in urls:\n",
        "        try:\n",
        "            results.append(evaluate_url(u, network_check=network_check, timeout=timeout))\n",
        "        except Exception as e:\n",
        "            results.append({\"score\": 0.0, \"explanation\": f\"Internal error: {e}\"})\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "1JNMgGwrGpO5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity tests demonstrating consistent JSON, malformed inputs, and different URL types.\n",
        "\n",
        "test_urls = [\n",
        "    \"https://www.nytimes.com\",\n",
        "    \"http://example.com\",\n",
        "    \"bbc.com/news\",                        # missing scheme -> we auto-prepend https://\n",
        "    \"https://bit.ly/xyz\",\n",
        "    \"https://xn--pt-eka.com\",             # punycode-ish pattern\n",
        "    \"https://some---weird---domain12345.net/path?x=1&y=2&z=3&a=4&b=5&utm_source=abc\",\n",
        "    \"ftp://data.server.com/file.csv\",     # non-http(s)\n",
        "    \"http:/bad\",                          # malformed\n",
        "    \"\",                                   # empty\n",
        "    None                                  # non-string\n",
        "]\n",
        "\n",
        "print(\"=== Functional tests (network_check=False for speed/reliability in class) ===\")\n",
        "for u in test_urls:\n",
        "    result = evaluate_url(u, network_check=False)\n",
        "    # Enforce required JSON shape\n",
        "    assert isinstance(result, dict) and \"score\" in result and \"explanation\" in result\n",
        "    assert isinstance(result[\"score\"], float)\n",
        "    assert isinstance(result[\"explanation\"], str)\n",
        "    print(u, \"->\", json.dumps(result, ensure_ascii=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GF9kkNU0FYIa",
        "outputId": "44b2be61-18bc-462b-a9ec-bd4465184fab"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Functional tests (network_check=False for speed/reliability in class) ===\n",
            "https://www.nytimes.com -> {\"score\": 0.8022, \"explanation\": \"scheme=https, domain=www.nytimes.com | + HTTPS detected (+0.6) | + recognized reputable domain (+0.8)\"}\n",
            "http://example.com -> {\"score\": 0.5498, \"explanation\": \"scheme=http, domain=example.com | + HTTP detected (+0.2)\"}\n",
            "bbc.com/news -> {\"score\": 0.8022, \"explanation\": \"scheme=https, domain=bbc.com | + HTTPS detected (+0.6) | + recognized reputable domain (+0.8)\"}\n",
            "https://bit.ly/xyz -> {\"score\": 0.4502, \"explanation\": \"scheme=https, domain=bit.ly | + HTTPS detected (+0.6) | - URL shortener detected (-0.8)\"}\n",
            "https://xn--pt-eka.com -> {\"score\": 0.3775, \"explanation\": \"scheme=https, domain=xn--pt-eka.com | + HTTPS detected (+0.6) | - punycode domain (-0.6) | - many hyphens in domain (3) (-0.5)\"}\n",
            "https://some---weird---domain12345.net/path?x=1&y=2&z=3&a=4&b=5&utm_source=abc -> {\"score\": 0.3543, \"explanation\": \"scheme=https, domain=some---weird---domain12345.net | + HTTPS detected (+0.6) | - many hyphens in domain (6) (-0.5) | - many digits in domain (5) (-0.4) | - many query parameters (6) (-0.2) | - common tracking params present (-0.1)\"}\n",
            "ftp://data.server.com/file.csv -> {\"score\": 0.4502, \"explanation\": \"scheme=ftp, domain=data.server.com | - Non-HTTP(S) scheme 'ftp' (-0.2)\"}\n",
            "http:/bad -> {\"score\": 0.6457, \"explanation\": \"scheme=https, domain=http | + HTTPS detected (+0.6)\"}\n",
            " -> {\"score\": 0.0, \"explanation\": \"Empty string.\"}\n",
            "None -> {\"score\": 0.0, \"explanation\": \"Input is not a string.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate pure-heuristic speed from network overhead.\n",
        "\n",
        "bench_urls = [\n",
        "    \"nytimes.com\", \"reuters.com\", \"example.com\", \"bit.ly/abc\",\n",
        "    \"some-long-domain-123456789.com/path?x=1&y=2&z=3&a=4&b=5&utm_source=abc\",\n",
        "] * 20  # 100 URLs total\n",
        "\n",
        "def bench(fn, label):\n",
        "    t0 = time.time()\n",
        "    _ = fn()\n",
        "    dt = time.time() - t0\n",
        "    print(f\"{label}: {dt:.3f}s\")\n",
        "\n",
        "bench(lambda: evaluate_urls(bench_urls, network_check=False), \"Heuristics-only (100 URLs)\")\n",
        "\n",
        "# Keep the network test small to avoid rate-limits/timeouts in class.\n",
        "small_network_urls = [\"https://www.nytimes.com\", \"https://www.bbc.com\", \"http://example.com\"]\n",
        "bench(lambda: evaluate_urls(small_network_urls, network_check=True, timeout=2.0), \"With HEAD checks (3 URLs)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGOSeuweHEsU",
        "outputId": "b6b2ad57-438d-491c-e65a-789455f98541"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Heuristics-only (100 URLs): 0.005s\n",
            "With HEAD checks (3 URLs): 0.375s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear demonstration of required JSON output.\n",
        "demo = evaluate_url(\"https://www.nature.com/articles\", network_check=False)\n",
        "print(json.dumps(demo, ensure_ascii=False, indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQPBpsqYHOE2",
        "outputId": "3750376c-159b-413a-c04a-2e80dd04868a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"score\": 0.8022,\n",
            "  \"explanation\": \"scheme=https, domain=www.nature.com | + HTTPS detected (+0.6) | + recognized reputable domain (+0.8)\"\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}